---
output_yaml:
  - _output.yml
---

# N Parameters {#n-parameters}

A new chapter in summer 2020. second add.

```{r include=FALSE}
knitr::opts_chunk$set(echo = FALSE, tidy = FALSE)
library(PPBDS.data)
library(rstanarm)
library(dplyr)
library(broom)
library(tidyverse)
```

<!-- 
intercept

Interactions --- use: income ~ party*something

heterogeneous treatment effects --- use:  att_start ~ treatment*something 
just a fancy way of saying interaction effects, but with a variable which us causal


What problems do we face? All the things that make modeling difficult. Why is this so hard? -->

<!-- Centering. -->

<!-- Might naively just take the value for each bucket. But that overfits! Need to put down some structure, like ordering. -->

<!-- income category, party id, pooling, age, -->

<!-- overfitting/underfitting bias/variance -->

<!-- We must have left bootstrapping behind by now. No more bootstraps, at least for the purpose of calculating uncertainty. (We will use it later for the purpose of out-of-sample testing and avoiding overfitting.) Key lesson is that overfitting is easy. You can't just estimate a value for each cell. You need to smooth and borrow strength. Of course, the only way to do that is with a Bayesian approach. Right? We don't want to get into hacked likelihood approaches. -->

<!-- cces looks perfect for this project. There are 400,000 rows, so it seems like you ought to have plenty of data for anything you want, but once you realize there are 51 states and 10 years, things get sparse fast. We only have 15 observations, for example, for Wyoming in 2007. Once you start subsetting by race and education, you have no choice but to start borrowing strength.  -->

<!-- So, just what will we use? rstanarm(). If so (and if we have not introduced it earlier), we can begin with seeing how it is similar to lm() and then expand. This means that, in one paramter chapter, we should be doing lm( ~ 1). In two parameter, lm( ~ treatment) --- if treatment is zero one --- or, perhaps better, lm( ~ -1 + treatment) if treatment is a factor/character with two levels. We might also have introduced  -->

## formatting linear models in R
In the previous chapter, linear models were created using the general format of `dependent variable ~ -1 + independent variable`. After running the regression on a model of this type, the resulting table would show coefficients for both parameters of the independent variable, for example Democrat and Republican. This method works fine when there are only one or two parameters in consideration, however now we will be moving onto *n* parameters and we will have to change the formula we use; specifically, we will be removing the -1 from the lm formula.

In order to remove the -1, we first have to understand the function of it in the linear regression formulas that you have seen previously. Using the `trains` data, when we use -1 in our formula and regress party on income, the table output lists both parameters and estimates their mean income values.

```{r}

lm(data = trains, income ~ -1 + party) %>% tidy(conf.int = TRUE)

```
<!-- Is there a way to make this output neater in the knit document? More of a typical regression table? -->
This table tells us that Democrats have an average income of $136,755.20, while Republicans have an average income of $167,368.40. 

Once we remove the -1 from the formula, the the regression table replaces one of the parameter terms with "(Intercept)". For example, if we use the same regression as above but remove the -1, the output table changes to this:
```{r}

lm(data = trains, income ~ party) %>% tidy(conf.int = TRUE)

```

Although the coefficients in this regression table are different than the ones above, the interpretation stays the same. The intercept still represents the average income of democrats, the default parameter, however the partyRepulican coefficient is now the difference between the mean income of republicans and democrats. The value of the mean republican income remains the same, however, but it is now calculated by adding the partyRepublican coefficient to the intercept estimate.

```{r}
136755.21 + 30613.21
```


## Adding parameters
We will now begin adding parameters to our regression models. The simplest way to do so is by adding another independent variable to the regression formula. For example, we can add gender to the same formula we used previously.

```{r}

lm(data = trains, income ~ party + gender) %>% tidy(conf.int = TRUE)

```

In this model, the intercept represents female democrats and tells us that the mean income for female democrats is $121,086.46. If we want the mean income for a femal republican, we would add the partyRepublican coefficient to the intercept estimate, which gives us a mean income of $152,707.60, or we can say that female republicans have a mean income that is $31,621.14 more than female democrats. The genderMale coefficient tells us the difference between the income of a female democrat and a male democrat. By adding this coefficient to the intercept value, we find that male democrats have a mean income of $148,942. In order to find the mean income of a male republican, we would have to add both the partyRepublican coefficient *and* the genderMale coefficient to the intercept, since both parameters apply. From this we find the mean income of a republican male is $180,563.10. 

## Interaction terms
Another way to add parameters to a linear regression formula is by incorporating interaction terms. 



## heterogeneous treatment effect
fancy way of saying interactions but with a variable that you believe is causal 



## 5 sources of uncertainty
style.Rmd

#### 3. Parameter Uncertainty
estimate of income coefficient
confidence interval gives the range of uncertainty
  - when dealing with a new observation, it is not the confidence interval
      - this is where you use posterior predict
      - difference between uncertainty about parameyer mean estimate but confidence interval for the mean is not equal to the estimate for the new observation

#### 4. Unmodeled Variation




## Rubin Causal Model
new female democrat shows up


## cces data

In this chapter we will be using the cces data, or Cooperative Congress Election Survey. The CCES is a 50,000+ person national stratified sample survey that consists of a pre- and post- election wave. In the pre-election wave, respondents complete two-thirds of the survey that asks about general political attitudes, various demographic factors, assessment of roll call voting choices, political information, and vote intentions. In the post-election wave, respondents complete the final third of the survey that consists mostly of items related to the election that just occurred.

Some of the key variables that are included in the data set are approval ratings of the elected officials, from the governor to the president, on a scale from "Strongly Disapprove" to "Strongly Approve". To quantify this data, the new variables `approval_pres_num`, `approval_rep_num`, `approval_sen1_num`, `approval_sen2_num`, and `approval_gov_num` have all been created and quantify the approval scale by ordering the responses from a 1 to a 5. Those who answered with "Strongly Disapprove" are a 1 on the approval scale, while those who answered with "Strongly Approve" are a 5 on the numerical approval scale. Those who are neutral answered with "Neither Approve Nor Disapprove" and are quantified as a 3 on the scale. Respondents who answered with "Never Heard / Not Sure" have been removed in order to improve the accuracy of the approval ratings.

```{r, include=FALSE}
ch9 <- PPBDS.data::cces



```
<!-- HV: How do I add these new variables to the data set for everyone to use? Do I include the code for that in the Markdown or do I instruct the readers how to create these variables themselves with the cces data they are given? 

DK: I have updated cces so that "approval" is presidential approval
-->

Other variables in the cces data include state, race, age, education level, gender, and ideology. The data taken spans from 2006 to 2018, although it should be noted that there are more observations in years with general elections.

## presidential approval; overall; by year; by state; by state x year x educ

## need rstanarm

## Rubin Causal Model

<!-- create numeric `rating` 1 to 4. Leave out Never heard. Might use percentage strongly approve. -->

<!-- discuss overall rating for entire date set. One parameter. Discuss. For each year. For each state. -->

<!-- basic lm -->

<!-- lm(data = cces, age ~ 1) %>% tidy(conf.int = TRUE) -->
<!-- lm(data = cces, age ~ -1 + state) %>% tidy(conf.int = TRUE) -->
<!-- lm(data = cces, age ~ -1 + as.factor(year)) %>% tidy(conf.int = TRUE) -->

<!-- obj <- lm(data = cces, age ~ -1 + state*as.factor(year)) %>% tidy(conf.int = TRUE) -->


<!-- Connecting parameters to real world concepts. What are we measuring? validity. -->

<!-- estimands -->




